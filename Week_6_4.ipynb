{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Применение Vowpal Wabbit к данным по посещению сайтов\n",
    "\n",
    "### 2.1. Подготовка данных\n",
    "\n",
    "**Далее посмотрим на Vowpal Wabbit в деле. Правда, в задаче нашего соревнования при бинарной классификации веб-сессий мы разницы не заметим – как по качеству, так и по скорости работы (хотя можете проверить), продемонстрируем всю резвость VW в задаче классификации на 400 классов. Исходные данные все те же самые, но выделено 400 пользователей, и решается задача их идентификации. Скачайте данные отсюда – файлы train_sessions_400users.csv и test_sessions_400users.csv.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from time import time\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяйте на свой путь к данным\n",
    "PATH_TO_DATA = 'capstone_user_identification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим обучающую и тестовую выборки. Можете заметить, что тестовые сессии здесь по времени четко отделены от сессий в обучающей выборке.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_400 = pd.read_csv(os.path.join(PATH_TO_DATA,'train_sessions_400users.csv'), \n",
    "                           index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_400 = pd.read_csv(os.path.join(PATH_TO_DATA,'test_sessions_400users.csv'), \n",
    "                           index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23713</td>\n",
       "      <td>2014-03-24 15:22:40</td>\n",
       "      <td>23720.0</td>\n",
       "      <td>2014-03-24 15:22:48</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:22:48</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:22:54</td>\n",
       "      <td>23720.0</td>\n",
       "      <td>2014-03-24 15:22:54</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-24 15:22:55</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:01</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:03</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:04</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:05</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8726</td>\n",
       "      <td>2014-04-17 14:25:58</td>\n",
       "      <td>8725.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>665.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>8727.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-04-17 14:26:01</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2014-04-17 14:26:01</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>2014-04-17 14:26:18</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>2014-04-17 14:26:47</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>2014-04-17 14:26:48</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>2014-03-21 10:12:24</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2014-03-21 10:12:36</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:12:54</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:13:01</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:13:24</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-21 10:13:36</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:13:54</td>\n",
       "      <td>309.0</td>\n",
       "      <td>2014-03-21 10:14:01</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:14:06</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:14:24</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1359</td>\n",
       "      <td>2013-12-13 09:52:28</td>\n",
       "      <td>925.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>2013-12-13 09:58:19</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>2013-12-13 09:58:19</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>2013-11-26 12:35:29</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:35:31</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2013-11-26 12:35:31</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:35:32</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2013-11-26 12:35:32</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-11-26 12:35:32</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2013-11-26 12:37:03</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:37:03</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2013-11-26 12:37:03</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:37:04</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1                time1    site2                time2    site3  \\\n",
       "session_id                                                                      \n",
       "1           23713  2014-03-24 15:22:40  23720.0  2014-03-24 15:22:48  23713.0   \n",
       "2            8726  2014-04-17 14:25:58   8725.0  2014-04-17 14:25:59    665.0   \n",
       "3             303  2014-03-21 10:12:24     19.0  2014-03-21 10:12:36    303.0   \n",
       "4            1359  2013-12-13 09:52:28    925.0  2013-12-13 09:54:34   1240.0   \n",
       "5              11  2013-11-26 12:35:29     85.0  2013-11-26 12:35:31     52.0   \n",
       "\n",
       "                          time3    site4                time4    site5  \\\n",
       "session_id                                                               \n",
       "1           2014-03-24 15:22:48  23713.0  2014-03-24 15:22:54  23720.0   \n",
       "2           2014-04-17 14:25:59   8727.0  2014-04-17 14:25:59     45.0   \n",
       "3           2014-03-21 10:12:54    303.0  2014-03-21 10:13:01    303.0   \n",
       "4           2013-12-13 09:54:34   1360.0  2013-12-13 09:54:34   1344.0   \n",
       "5           2013-11-26 12:35:31     85.0  2013-11-26 12:35:32     11.0   \n",
       "\n",
       "                          time5  ...                time6    site7  \\\n",
       "session_id                       ...                                 \n",
       "1           2014-03-24 15:22:54  ...  2014-03-24 15:22:55  23713.0   \n",
       "2           2014-04-17 14:25:59  ...  2014-04-17 14:26:01     45.0   \n",
       "3           2014-03-21 10:13:24  ...  2014-03-21 10:13:36    303.0   \n",
       "4           2013-12-13 09:54:34  ...  2013-12-13 09:54:34   1346.0   \n",
       "5           2013-11-26 12:35:32  ...  2013-11-26 12:35:32     11.0   \n",
       "\n",
       "                          time7    site8                time8    site9  \\\n",
       "session_id                                                               \n",
       "1           2014-03-24 15:23:01  23713.0  2014-03-24 15:23:03  23713.0   \n",
       "2           2014-04-17 14:26:01   5320.0  2014-04-17 14:26:18   5320.0   \n",
       "3           2014-03-21 10:13:54    309.0  2014-03-21 10:14:01    303.0   \n",
       "4           2013-12-13 09:54:34   1345.0  2013-12-13 09:54:34   1344.0   \n",
       "5           2013-11-26 12:37:03     85.0  2013-11-26 12:37:03     10.0   \n",
       "\n",
       "                          time9   site10               time10 user_id  \n",
       "session_id                                                             \n",
       "1           2014-03-24 15:23:04  23713.0  2014-03-24 15:23:05     653  \n",
       "2           2014-04-17 14:26:47   5320.0  2014-04-17 14:26:48     198  \n",
       "3           2014-03-21 10:14:06    303.0  2014-03-21 10:14:24      34  \n",
       "4           2013-12-13 09:58:19   1345.0  2013-12-13 09:58:19     601  \n",
       "5           2013-11-26 12:37:03     85.0  2013-11-26 12:37:04     273  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_400.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Видим, что в обучающей выборке 182793 сессий, в тестовой – 46473, и сессии действительно принадлежат 400 различным пользователям.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182793, 21), (46473, 20), 400)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_400.shape, test_df_400.shape, train_df_400['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vowpal Wabbit любит, чтоб метки классов были распределены от 1 до K, где K – число классов в задаче классификации (в нашем случае – 400). Поэтому придется применить LabelEncoder, да еще и +1 потом добавить (LabelEncoder переводит метки в диапозон от 0 до K-1). Потом надо будет применить обратное преобразование.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df_400.user_id\n",
    "class_encoder = preprocessing.LabelEncoder()\n",
    "y_for_vw = class_encoder.fit_transform(y)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Далее будем сравнивать VW с SGDClassifier и с логистической регрессией. Всем моделям этим нужна предобработка входных данных. Подготовьте для sklearn-моделей разреженные матрицы, как мы это делали в 5 части:**\n",
    "\n",
    "* объедините обучающиую и тестовую выборки\n",
    "* выберите только сайты (признаки от 'site1' до 'site10')\n",
    "* замените пропуски на нули (сайты у нас нумеровались с 0)\n",
    "* переведите в разреженный формат csr_matrix\n",
    "* разбейте обратно на обучающую и тестовую части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['site' + str(i) for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zmey56/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_test_df = pd.concat([train_df_400, test_df_400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df_sites = train_test_df[sites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81858"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df_sites.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df_sites = train_test_df_sites.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df_sites.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df_sites = train_test_df_sites.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229266, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df_sites.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = test_df_400[sites].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25082019\n",
    "\n",
    "def create_sparse_matrix(dataframe):\n",
    "    tmp_arr = np.array(dataframe)\n",
    "    row = 0\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "\n",
    "    for arr in tmp_arr:\n",
    "        #print(arr)\n",
    "        for i, val in enumerate(arr):\n",
    "            if val != 0:                \n",
    "                data.append(val)\n",
    "                cols.append(i)\n",
    "                rows.append(row)\n",
    "        row = row + 1\n",
    "        \n",
    "    return(sps.coo_matrix((data, (rows, cols))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DF size: (182793, 10)\n",
      "Test DF size: (46473, 10)\n",
      "Target size: (182793,)\n",
      "Time elapse:  1.8315954208374023\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "\n",
    "idx_split = train_df_400.shape[0]\n",
    "\n",
    "#tmp_sparse = csr_matrix(create_sparse_matrix(tmp))\n",
    "\n",
    "train_test_sparse = csr_matrix(create_sparse_matrix(train_test_df_sites))\n",
    "\n",
    "X_train_sparse = train_test_sparse[:idx_split, :]\n",
    "X_test_sparse = train_test_sparse[idx_split:,:]\n",
    "\n",
    "#y = train_df.target\n",
    "\n",
    "print('Train DF size: {0}\\nTest DF size: {1}\\nTarget size: {2}'.format(\n",
    "    str(X_train_sparse.shape), str(X_test_sparse.shape), str(y.shape)))\n",
    "\n",
    "print(\"Time elapse: \", time() - t_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Валидация по отложенной выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выделим обучающую (70%) и отложенную (30%) части исходной обучающей выборки. Данные не перемешиваем, учитываем, что сессии отсортированы по времени.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_share = int(.7 * train_df_400.shape[0])\n",
    "train_df_part = train_df_400[sites].iloc[:train_share, :]\n",
    "valid_df = train_df_400[sites].iloc[train_share:, :]\n",
    "X_train_part_sparse = X_train_sparse[:train_share, :]\n",
    "X_valid_sparse = X_train_sparse[train_share:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_part = y[:train_share]\n",
    "y_valid = y[train_share:]\n",
    "y_train_part_for_vw = y_for_vw[:train_share]\n",
    "y_valid_for_vw = y_for_vw[train_share:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182793,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_vw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию, arrays_to_vw, переводящую обучающую выборку в формат Vowpal Wabbit.\n",
    "\n",
    "Вход:\n",
    "\n",
    "* X – матрица NumPy (обучающая выборка)\n",
    "* y (необяз.) - вектор ответов (NumPy). Необязателен, поскольку тестовую матрицу будем обрабатывать этой же функцией\n",
    "* train – флаг, True в случае обучающей выборки, False – в случае тестовой выборки\n",
    "* out_file – путь к файлу .vw, в который будет произведена запись\n",
    "\n",
    "Детали:\n",
    "\n",
    "* надо пройтись по всем строкам матрицы X и записать через пробел все значения, предварительно добавив вперед нужную метку класса из вектора y и знак-разделитель |\n",
    "* в тестовой выборке на месте меток целевого класса можно писать произвольные, допустим, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrays_to_vw(X, y=None, train=True, out_file='tmp.vw'):\n",
    "    X = np.nan_to_num(X)\n",
    "    X = X.astype(int)\n",
    "    \n",
    "    with open(out_file, 'w') as f:\n",
    "        print(X.shape)\n",
    "        for i in range(X.shape[0]):\n",
    "            string =  ' '.join([str(x) for x in X[i]])\n",
    "            if y is None:\n",
    "                #print(\"NONE\")\n",
    "                f.write(str(1) + \" | \" + string + \"\\n\")\n",
    "            else:\n",
    "                f.write(str(y[i]) + \" | \" + string + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примените написанную функцию к части обучащей выборки (train_df_part, y_train_part_for_vw), к отложенной выборке (valid_df, y_valid_for_vw), ко всей обучающей выборке и ко всей тестовой выборке. Обратите внимание, что на вход наш метод принимает именно матрицы и вектора NumPy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127955, 10)\n",
      "(54838, 10)\n",
      "(182793, 10)\n",
      "(46473, 10)\n",
      "Time elapse:  3.395047664642334\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "#tmp = create_sparse_matrix(train_df_part)\n",
    "\n",
    "\n",
    "arrays_to_vw(train_df_part.values, y_train_part_for_vw, True, 'kaggle_data/train_part.vw')\n",
    "arrays_to_vw(valid_df.values, y_valid_for_vw, False, 'kaggle_data/valid.vw')\n",
    "arrays_to_vw(train_df_400[sites].values, y_for_vw, True, 'kaggle_data/train.vw')\n",
    "arrays_to_vw(test_df_400[sites].values, None, False, 'kaggle_data/test.vw')\n",
    "\n",
    "print(\"Time elapse: \", time() - t_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель Vowpal Wabbitна выборке train_part.vw. Укажите, что решается задача классификации с 400 классами (--oaa), сделайте 3 прохода по выборке (--passes). Задайте некоторый кэш-файл (--cache_file, можно просто указать флаг -c), так VW будет быстрее делать все следующие после первого проходы по выборке (прошлый кэш-файл удаляется с помощью аргумента -k). Также укажите значение параметра b=26. Это число бит, используемых для хэширования, в данном случае нужно больше, чем 18 по умолчанию. Наконец, укажите random_seed=17. Остальные параметры пока не меняйте, далее уже в свободном режиме соревнования можете попробовать другие функции потерь.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_vw = os.path.join(PATH_TO_DATA, 'train_part.vw')\n",
    "valid_vw = os.path.join(PATH_TO_DATA, 'valid.vw')\n",
    "train_vw = os.path.join(PATH_TO_DATA, 'train.vw')\n",
    "test_vw = os.path.join(PATH_TO_DATA, 'test.vw')\n",
    "model = os.path.join(PATH_TO_DATA, 'vw_model.vw')\n",
    "pred = os.path.join(PATH_TO_DATA, 'vw_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 | 23713 23720 23713 23713 23720 23713 23713 23713 23713 23713\r\n",
      "82 | 8726 8725 665 8727 45 8725 45 5320 5320 5320\r\n",
      "16 | 303 19 303 303 303 303 303 309 303 303\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 kaggle_data/train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 | 9 304 308 307 91 308 312 300 305 309\r\n",
      "1 | 838 504 68 11 838 11 838 886 27 305\r\n",
      "1 | 190 192 8 189 191 189 190 2375 192 8\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 kaggle_data/test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 | 23713 23720 23713 23713 23720 23713 23713 23713 23713 23713\r\n",
      "82 | 8726 8725 665 8727 45 8725 45 5320 5320 5320\r\n",
      "16 | 303 19 303 303 303 303 303 309 303 303\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 kaggle_data/train_part.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 | 7 923 923 923 11 924 7 924 838 7\r\n",
      "160 | 91 198 11 11 302 91 668 311 310 91\r\n",
      "312 | 27085 848 118 118 118 118 11 118 118 118\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 kaggle_data/valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = kaggle_data_result/model.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = kaggle_data/train_part.vw.cache\n",
      "Reading datafile = kaggle_data/train_part.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      262        1       11\n",
      "1.000000 1.000000            2            2.0       82      262       11\n",
      "1.000000 1.000000            4            4.0      241      262       11\n",
      "1.000000 1.000000            8            8.0      352      262       11\n",
      "1.000000 1.000000           16           16.0      135       16       11\n",
      "1.000000 1.000000           32           32.0       71      112       11\n",
      "0.968750 0.937500           64           64.0      358      231       11\n",
      "0.976562 0.984375          128          128.0      348      346       11\n",
      "0.941406 0.906250          256          256.0      202      202       11\n",
      "0.947266 0.953125          512          512.0       30        1       11\n",
      "0.925781 0.904297         1024         1024.0       36      290       11\n",
      "0.908203 0.890625         2048         2048.0       21      128       11\n",
      "0.880127 0.852051         4096         4096.0       80      229       11\n",
      "0.856323 0.832520         8192         8192.0      307      356       11\n",
      "0.828003 0.799683        16384        16384.0       59      193       11\n",
      "0.795441 0.762878        32768        32768.0      262       30       11\n",
      "0.760468 0.725494        65536        65536.0      171      238       11\n",
      "0.724008 0.724008       131072       131072.0        6        6       11 h\n",
      "0.697339 0.670672       262144       262144.0       12       12       11 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 115160\n",
      "passes used = 3\n",
      "weighted example sum = 345480.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.661352 h\n",
      "total feature number = 3800280\n"
     ]
    }
   ],
   "source": [
    "!vw --oaa 400 --passes 3 -c -k kaggle_data/train_part.vw -b 26 -f  kaggle_data_result/model.vw --random_seed 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vw -i kaggle_data_result/model.vw -t -d kaggle_data/valid.vw -p kaggle_data_result/vw_valid_pred.csv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv('kaggle_data_result/vw_valid_pred.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34541741128414605"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_valid_for_vw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = kaggle_data/model.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = kaggle_data/train_part.vw.cache\n",
      "Reading datafile = kaggle_data/train_part.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      262        1       11\n",
      "1.000000 1.000000            2            2.0       82      262       11\n",
      "1.000000 1.000000            4            4.0      241      262       11\n",
      "1.000000 1.000000            8            8.0      352      262       11\n",
      "1.000000 1.000000           16           16.0      135       16       11\n",
      "1.000000 1.000000           32           32.0       71      112       11\n",
      "0.968750 0.937500           64           64.0      358      231       11\n",
      "0.976562 0.984375          128          128.0      348      346       11\n",
      "0.941406 0.906250          256          256.0      202      202       11\n",
      "0.947266 0.953125          512          512.0       30        1       11\n",
      "0.925781 0.904297         1024         1024.0       36      290       11\n",
      "0.908203 0.890625         2048         2048.0       21      128       11\n",
      "0.880127 0.852051         4096         4096.0       80      229       11\n",
      "0.856323 0.832520         8192         8192.0      307      356       11\n",
      "0.828003 0.799683        16384        16384.0       59      193       11\n",
      "0.795441 0.762878        32768        32768.0      262       30       11\n",
      "0.760468 0.725494        65536        65536.0      171      238       11\n",
      "0.724008 0.724008       131072       131072.0        6        6       11 h\n",
      "0.697339 0.670672       262144       262144.0       12       12       11 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 115160\n",
      "passes used = 3\n",
      "weighted example sum = 345480.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.661352 h\n",
      "total feature number = 3800280\n"
     ]
    }
   ],
   "source": [
    "!vw --oaa 400 --passes 3 -c -k kaggle_data/train_part.vw -b 26 -f  kaggle_data/model.vw --random_seed 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите прогнозы на выборке valid.vw в vw_valid_pred.csv.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = kaggle_data/vw_valid_pred.csv\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = kaggle_data/valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        4      188       11\n",
      "1.000000 1.000000            2            2.0      160      220       11\n",
      "0.750000 0.500000            4            4.0      143      143       11\n",
      "0.750000 0.750000            8            8.0      247      247       11\n",
      "0.687500 0.625000           16           16.0      341       30       11\n",
      "0.593750 0.500000           32           32.0      237      237       11\n",
      "0.609375 0.625000           64           64.0      178      178       11\n",
      "0.640625 0.671875          128          128.0      132      228       11\n",
      "0.656250 0.671875          256          256.0       14       14       11\n",
      "0.646484 0.636719          512          512.0      370      370       11\n",
      "0.663086 0.679688         1024         1024.0      189      189       11\n",
      "0.655762 0.648438         2048         2048.0      311      311       11\n",
      "0.657227 0.658691         4096         4096.0      195      318       11\n",
      "0.660156 0.663086         8192         8192.0      171      195       11\n",
      "0.657654 0.655151        16384        16384.0      362       51       11\n",
      "0.655121 0.652588        32768        32768.0      248      248       11\n",
      "\n",
      "finished run\n",
      "number of examples = 54838\n",
      "weighted example sum = 54838.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.654583\n",
      "total feature number = 603218\n"
     ]
    }
   ],
   "source": [
    "!vw -t -i kaggle_data/model.vw kaggle_data/valid.vw -p kaggle_data/vw_valid_pred.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Считайте прогнозы kaggle_data/vw_valid_pred.csv из файла и посмотрите на долю правильных ответов на отложенной части.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv('kaggle_data/vw_valid_pred.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Вопрос 1.</span>  Посчитайте долю правильных ответов на отложенной выборке для Vowpal Wabbit, округлите до 3 знаков после запятой.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34541741128414605"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred.values, y_valid_for_vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Вопрос 2.</span>  Посчитайте долю правильных ответов на отложенной выборке для SGD, округлите до 3 знаков после запятой.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = kaggle_data/model_sgd.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = kaggle_data/train_part.vw.cache\n",
      "Reading datafile = kaggle_data/train_part.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      262        1       11\n",
      "1.000000 1.000000            2            2.0       82      262       11\n",
      "1.000000 1.000000            4            4.0      241       16       11\n",
      "1.000000 1.000000            8            8.0      352      397       11\n",
      "1.000000 1.000000           16           16.0      135       16       11\n",
      "1.000000 1.000000           32           32.0       71      112       11\n",
      "0.984375 0.968750           64           64.0      358        1       11\n",
      "0.984375 0.984375          128          128.0      348      281       11\n",
      "0.957031 0.929688          256          256.0      202      202       11\n",
      "0.953125 0.949219          512          512.0       30        1       11\n",
      "0.946289 0.939453         1024         1024.0       36      290       11\n",
      "0.934082 0.921875         2048         2048.0       21        1       11\n",
      "0.918701 0.903320         4096         4096.0       80      134       11\n",
      "0.899414 0.880127         8192         8192.0      307        1       11\n",
      "0.881531 0.863647        16384        16384.0       59      193       11\n",
      "0.858307 0.835083        32768        32768.0      262       30       11\n",
      "0.830536 0.802765        65536        65536.0      171        1       11\n",
      "0.796251 0.796251       131072       131072.0        6        1       11 h\n",
      "0.769133 0.742017       262144       262144.0       12       12       11 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 115160\n",
      "passes used = 3\n",
      "weighted example sum = 345480.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.725518 h\n",
      "total feature number = 3800280\n"
     ]
    }
   ],
   "source": [
    "!vw --oaa 400 --passes 3 -c -k kaggle_data/train_part.vw -b 26 -f kaggle_data/model_sgd.vw --sgd --random_seed 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = kaggle_data/vw_valid_pred_sgd.csv\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = kaggle_data/valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        4      188       11\n",
      "1.000000 1.000000            2            2.0      160      220       11\n",
      "0.750000 0.500000            4            4.0      143      143       11\n",
      "0.750000 0.750000            8            8.0      247      247       11\n",
      "0.875000 1.000000           16           16.0      341      318       11\n",
      "0.687500 0.500000           32           32.0      237      237       11\n",
      "0.703125 0.718750           64           64.0      178      178       11\n",
      "0.726562 0.750000          128          128.0      132      228       11\n",
      "0.734375 0.742188          256          256.0       14       14       11\n",
      "0.716797 0.699219          512          512.0      370      370       11\n",
      "0.734375 0.751953         1024         1024.0      189      189       11\n",
      "0.721680 0.708984         2048         2048.0      311        1       11\n",
      "0.715088 0.708496         4096         4096.0      195      318       11\n",
      "0.717651 0.720215         8192         8192.0      171      195       11\n",
      "0.715942 0.714233        16384        16384.0      362      181       11\n",
      "0.716156 0.716370        32768        32768.0      248      248       11\n",
      "\n",
      "finished run\n",
      "number of examples = 54838\n",
      "weighted example sum = 54838.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.716656\n",
      "total feature number = 603218\n"
     ]
    }
   ],
   "source": [
    "!vw -t -i kaggle_data/model_sgd.vw kaggle_data/valid.vw -p kaggle_data/vw_valid_pred_sgd.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2833436668003939"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_sgd = pd.read_csv('kaggle_data/vw_valid_pred_sgd.csv', header=None)\n",
    "accuracy_score(y_pred_sgd.values, y_valid_for_vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Вопрос 3.</span>  Посчитайте долю правильных ответов на отложенной выборке для логистической регрессии, округлите до 3 знаков после запятой.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = kaggle_data/model_log.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = kaggle_data/train_part.vw.cache\n",
      "Reading datafile = kaggle_data/train_part.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      262        1       11\n",
      "1.000000 1.000000            2            2.0       82      262       11\n",
      "1.000000 1.000000            4            4.0      241      262       11\n",
      "1.000000 1.000000            8            8.0      352      262       11\n",
      "1.000000 1.000000           16           16.0      135       16       11\n",
      "1.000000 1.000000           32           32.0       71      112       11\n",
      "0.984375 0.968750           64           64.0      358      176       11\n",
      "0.984375 0.984375          128          128.0      348      176       11\n",
      "0.949219 0.914062          256          256.0      202      202       11\n",
      "0.947266 0.945312          512          512.0       30      144       11\n",
      "0.932617 0.917969         1024         1024.0       36      290       11\n",
      "0.903320 0.874023         2048         2048.0       21       21       11\n",
      "0.877930 0.852539         4096         4096.0       80       64       11\n",
      "0.852417 0.826904         8192         8192.0      307      144       11\n",
      "0.821655 0.790894        16384        16384.0       59       59       11\n",
      "0.786224 0.750793        32768        32768.0      262       30       11\n",
      "0.751724 0.717224        65536        65536.0      171       59       11\n",
      "0.713089 0.713089       131072       131072.0        6        6       11 h\n",
      "0.687416 0.661746       262144       262144.0       12       12       11 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 115160\n",
      "passes used = 3\n",
      "weighted example sum = 345480.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.651192 h\n",
      "total feature number = 3800280\n"
     ]
    }
   ],
   "source": [
    "!vw --oaa 400 --passes 3 -c -k kaggle_data/train_part.vw -b 26 -f kaggle_data/model_log.vw --loss_function logistic --random_seed 17 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = kaggle_data/vw_valid_pred_log.csv\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = kaggle_data/valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        4      188       11\n",
      "1.000000 1.000000            2            2.0      160      385       11\n",
      "0.750000 0.500000            4            4.0      143      143       11\n",
      "0.500000 0.250000            8            8.0      247      247       11\n",
      "0.687500 0.875000           16           16.0      341       30       11\n",
      "0.593750 0.500000           32           32.0      237      237       11\n",
      "0.593750 0.593750           64           64.0      178      178       11\n",
      "0.609375 0.625000          128          128.0      132      160       11\n",
      "0.625000 0.640625          256          256.0       14       14       11\n",
      "0.626953 0.628906          512          512.0      370      370       11\n",
      "0.648438 0.669922         1024         1024.0      189      189       11\n",
      "0.651855 0.655273         2048         2048.0      311      348       11\n",
      "0.644775 0.637695         4096         4096.0      195      397       11\n",
      "0.650757 0.656738         8192         8192.0      171       59       11\n",
      "0.647034 0.643311        16384        16384.0      362        2       11\n",
      "0.646301 0.645569        32768        32768.0      248      248       11\n",
      "\n",
      "finished run\n",
      "number of examples = 54838\n",
      "weighted example sum = 54838.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.645410\n",
      "total feature number = 603218\n"
     ]
    }
   ],
   "source": [
    "!vw -t -i kaggle_data/model_log.vw kaggle_data/valid.vw -p kaggle_data/vw_valid_pred_log.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3545898829278967"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_log = pd.read_csv('kaggle_data/vw_valid_pred_log.csv', header=None)\n",
    "accuracy_score(y_pred_log.values, y_valid_for_vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Вопрос 4.</span> Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard) для Vowpal Wabbit?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = kaggle_data/vw_valid_pred_final.csv\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = kaggle_data/test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        1       99       11\n",
      "1.000000 1.000000            2            2.0        1      387       11\n",
      "1.000000 1.000000            4            4.0        1       52       11\n",
      "1.000000 1.000000            8            8.0        1      137       11\n",
      "1.000000 1.000000           16           16.0        1      273       11\n",
      "1.000000 1.000000           32           32.0        1       67       11\n",
      "0.984375 0.968750           64           64.0        1      244       11\n",
      "0.992188 1.000000          128          128.0        1      318       11\n",
      "0.996094 1.000000          256          256.0        1      318       11\n",
      "0.994141 0.992188          512          512.0        1      284       11\n",
      "0.992188 0.990234         1024         1024.0        1      202       11\n",
      "0.993652 0.995117         2048         2048.0        1      181       11\n",
      "0.994629 0.995605         4096         4096.0        1      313       11\n",
      "0.995117 0.995605         8192         8192.0        1       99       11\n",
      "0.995544 0.995972        16384        16384.0        1      326       11\n",
      "0.994537 0.993530        32768        32768.0        1       74       11\n",
      "\n",
      "finished run\n",
      "number of examples = 46473\n",
      "weighted example sum = 46473.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.994814\n",
      "total feature number = 511203\n"
     ]
    }
   ],
   "source": [
    "!vw -t -i kaggle_data/model.vw kaggle_data/test.vw -p kaggle_data/vw_valid_pred_final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv('kaggle_data/vw_valid_pred_final.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = range(1, len(y_pred)+1)\n",
    "df = pd.DataFrame(pd.Series(data), columns=['session_id'])\n",
    "df['user_id'] = class_encoder.inverse_transform((y_pred-1).values.ravel())\n",
    "df = df.set_index('session_id')\n",
    "df.to_csv('kaggle_data/first_vw_submission_final.csv', index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Вопрос 5.</span> Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard) для SGD?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = kaggle_data/model_sgd.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = kaggle_data/train.vw.cache\n",
      "Reading datafile = kaggle_data/train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      262        1       11\n",
      "1.000000 1.000000            2            2.0       82      262       11\n",
      "1.000000 1.000000            4            4.0      241       16       11\n",
      "1.000000 1.000000            8            8.0      352      397       11\n",
      "1.000000 1.000000           16           16.0      135       16       11\n",
      "1.000000 1.000000           32           32.0       71      112       11\n",
      "0.984375 0.968750           64           64.0      358        1       11\n",
      "0.984375 0.984375          128          128.0      348      281       11\n",
      "0.957031 0.929688          256          256.0      202      202       11\n",
      "0.953125 0.949219          512          512.0       30        1       11\n",
      "0.946289 0.939453         1024         1024.0       36      290       11\n",
      "0.934082 0.921875         2048         2048.0       21        1       11\n",
      "0.918701 0.903320         4096         4096.0       80      134       11\n",
      "0.899414 0.880127         8192         8192.0      307        1       11\n",
      "0.881531 0.863647        16384        16384.0       59      193       11\n",
      "0.858307 0.835083        32768        32768.0      262       30       11\n",
      "0.830536 0.802765        65536        65536.0      171        1       11\n",
      "0.799896 0.769257       131072       131072.0      180      245       11\n",
      "0.766600 0.766600       262144       262144.0       88      221       11 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 164514\n",
      "passes used = 3\n",
      "weighted example sum = 493542.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.707533 h\n",
      "total feature number = 5428962\n"
     ]
    }
   ],
   "source": [
    "!vw --oaa 400 --passes 3 -c -k kaggle_data/train.vw -b 26 -f kaggle_data/model_sgd.vw --sgd --random_seed 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = kaggle_data/vw_valid_pred_sgd_3.csv\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = kaggle_data/test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        1      207       11\n",
      "1.000000 1.000000            2            2.0        1       21       11\n",
      "1.000000 1.000000            4            4.0        1      388       11\n",
      "1.000000 1.000000            8            8.0        1      193       11\n",
      "0.937500 0.875000           16           16.0        1      273       11\n",
      "0.906250 0.875000           32           32.0        1      388       11\n",
      "0.875000 0.843750           64           64.0        1       25       11\n",
      "0.859375 0.843750          128          128.0        1       91       11\n",
      "0.882812 0.906250          256          256.0        1       91       11\n",
      "0.857422 0.832031          512          512.0        1      312       11\n",
      "0.852539 0.847656         1024         1024.0        1      202       11\n",
      "0.853516 0.854492         2048         2048.0        1      396       11\n",
      "0.861572 0.869629         4096         4096.0        1       21       11\n",
      "0.865601 0.869629         8192         8192.0        1      137       11\n",
      "0.864380 0.863159        16384        16384.0        1      326       11\n",
      "0.864838 0.865295        32768        32768.0        1       10       11\n",
      "\n",
      "finished run\n",
      "number of examples = 46473\n",
      "weighted example sum = 46473.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.864696\n",
      "total feature number = 511203\n"
     ]
    }
   ],
   "source": [
    "!vw -t -i kaggle_data/model_sgd.vw kaggle_data/test.vw -p kaggle_data/vw_valid_pred_sgd_3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sgd = pd.read_csv('kaggle_data/vw_valid_pred_sgd_3.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = range(1, len(y_pred_sgd)+1)\n",
    "df = pd.DataFrame(pd.Series(data), columns=['session_id'])\n",
    "df['user_id'] = class_encoder.inverse_transform((y_pred_sgd-1).values.ravel())\n",
    "df = df.set_index('session_id')\n",
    "df.to_csv('kaggle_data/second_vw_submission_1.csv', index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Вопрос 6.</span> Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard) для логистической регрессии?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = kaggle_data/model_log.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = kaggle_data/train.vw.cache\n",
      "Reading datafile = kaggle_data/train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      262        1       11\n",
      "1.000000 1.000000            2            2.0       82      262       11\n",
      "1.000000 1.000000            4            4.0      241      262       11\n",
      "1.000000 1.000000            8            8.0      352      262       11\n",
      "1.000000 1.000000           16           16.0      135       16       11\n",
      "1.000000 1.000000           32           32.0       71      112       11\n",
      "0.984375 0.968750           64           64.0      358      176       11\n",
      "0.984375 0.984375          128          128.0      348      176       11\n",
      "0.949219 0.914062          256          256.0      202      202       11\n",
      "0.947266 0.945312          512          512.0       30      144       11\n",
      "0.932617 0.917969         1024         1024.0       36      290       11\n",
      "0.903320 0.874023         2048         2048.0       21       21       11\n",
      "0.877930 0.852539         4096         4096.0       80       64       11\n",
      "0.852417 0.826904         8192         8192.0      307      144       11\n",
      "0.821655 0.790894        16384        16384.0       59       59       11\n",
      "0.786224 0.750793        32768        32768.0      262       30       11\n",
      "0.751724 0.717224        65536        65536.0      171       59       11\n",
      "0.716789 0.681854       131072       131072.0      180      159       11\n",
      "0.684646 0.684646       262144       262144.0       88       88       11 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 164514\n",
      "passes used = 3\n",
      "weighted example sum = 493542.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.634499 h\n",
      "total feature number = 5428962\n"
     ]
    }
   ],
   "source": [
    "!vw --oaa 400 --passes 3 -c -k kaggle_data/train.vw -b 26 -f kaggle_data/model_log.vw --loss_function logistic --random_seed 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = kaggle_data/vw_valid_pred_log_2.csv\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = kaggle_data/test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        1      310       11\n",
      "1.000000 1.000000            2            2.0        1       59       11\n",
      "1.000000 1.000000            4            4.0        1      265       11\n",
      "1.000000 1.000000            8            8.0        1      137       11\n",
      "1.000000 1.000000           16           16.0        1      144       11\n",
      "1.000000 1.000000           32           32.0        1      333       11\n",
      "1.000000 1.000000           64           64.0        1      126       11\n",
      "1.000000 1.000000          128          128.0        1      352       11\n",
      "1.000000 1.000000          256          256.0        1      112       11\n",
      "0.996094 0.992188          512          512.0        1      397       11\n",
      "0.995117 0.994141         1024         1024.0        1      202       11\n",
      "0.995605 0.996094         2048         2048.0        1      181       11\n",
      "0.997070 0.998535         4096         4096.0        1      263       11\n",
      "0.997437 0.997803         8192         8192.0        1       99       11\n",
      "0.997559 0.997681        16384        16384.0        1      326       11\n",
      "0.997162 0.996765        32768        32768.0        1       10       11\n",
      "\n",
      "finished run\n",
      "number of examples = 46473\n",
      "weighted example sum = 46473.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.997332\n",
      "total feature number = 511203\n"
     ]
    }
   ],
   "source": [
    "!vw -t -i kaggle_data/model_log.vw kaggle_data/test.vw -p kaggle_data/vw_valid_pred_log_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = pd.read_csv('kaggle_data/vw_valid_pred_log_2.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = range(1, len(y_pred_log)+1)\n",
    "df = pd.DataFrame(pd.Series(data), columns=['session_id'])\n",
    "df['user_id'] = class_encoder.inverse_transform((y_pred_log-1).values.ravel())\n",
    "df = df.set_index('session_id')\n",
    "df.to_csv('kaggle_data/third_vw_submission.csv', index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_logit = SGDClassifier(random_state=17, n_jobs=-1, loss='log', max_iter=3, n_iter=3)\n",
    "# или \n",
    "sgd_logit = SGDClassifier(random_state=17, n_jobs=-1, loss='log', max_iter=3)\n",
    "\n",
    "sgd_logit.fit(trainf_df_400_sparse, y_for_vw)\n",
    "sgd_predict_values = sgd_logit.predict(test_df_400_sparse)\n",
    "sgd_logit_test_pred = class_encoder.inverse_transform(sgd_predict_values - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_logit = SGDClassifier(random_state=17, n_jobs=-1, loss='log', max_iter=3, n_iter_no_change=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=3,\n",
       "              n_iter_no_change=3, n_jobs=-1, penalty='l2', power_t=0.5,\n",
       "              random_state=17, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_logit.fit(X_train_sparse, y_for_vw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_predict_values = sgd_logit.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_logit_test_pred = class_encoder.inverse_transform(sgd_predict_values - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = range(1, len(sgd_logit_test_pred)+1)\n",
    "df = pd.DataFrame(pd.Series(data), columns=['session_id'])\n",
    "df['user_id'] = sgd_logit_test_pred\n",
    "df = df.set_index('session_id')\n",
    "df.to_csv('kaggle_data/third_vw_submission_1.csv', index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_logit = SGDClassifier(loss='log', random_state=17, n_jobs=-1, max_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_logit.fit(X_train_part_sparse, y_train_part)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
